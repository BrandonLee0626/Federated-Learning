{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS-CRBVf5cV_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNPP9_Vu65oP",
        "outputId": "c1bd7552-1cbf-46a7-907e-57b2fbe662e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using PyTorch version: 2.4.1+cu121  Device: cpu\n",
            "BATCH_SIZE: 32\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:04<00:00, 1983792.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 449823.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 4094147.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2111095.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    DEVICE = torch.device('cpu')\n",
        "\n",
        "print(\"Using PyTorch version:\", torch.__version__,' Device:', DEVICE)\n",
        "\n",
        "BATCH_SIZE = int(input('BATCH_SIZE: '))\n",
        "\n",
        "train_dataset = datasets.MNIST(root = \"../data/MNIST\",\n",
        "                               train = True,\n",
        "                               download = True,\n",
        "                               transform = transforms.ToTensor())\n",
        "\n",
        "test_dataset = datasets.MNIST(root = \"../data/MNIST\",\n",
        "                              train = False,\n",
        "                              transform = transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = BATCH_SIZE,\n",
        "                                           shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = BATCH_SIZE,\n",
        "                                          shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsIlDoZr68ce"
      },
      "outputs": [],
      "source": [
        "def creat_clients(num_clients=10, initial='clients'):\n",
        "    client_names = [f'{initial}_{i+1}' for i in range(num_clients)]\n",
        "\n",
        "    size = len(train_dataset) // num_clients\n",
        "    shards = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                         batch_size = size,\n",
        "                                         shuffle = True)\n",
        "\n",
        "    assert(len(shards) == len(client_names))\n",
        "\n",
        "    return {client_names[i] : data for (i, data) in enumerate(shards)}\n",
        "\n",
        "clients = creat_clients()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kQmbadg6_kb"
      },
      "outputs": [],
      "source": [
        "def batch_data(data_shard, BATCH_SIZE):\n",
        "    dataset = torch.utils.data.TensorDataset(data_shard[0], data_shard[1])\n",
        "    return torch.utils.data.DataLoader(dataset = dataset,\n",
        "                                       batch_size = BATCH_SIZE,\n",
        "                                       shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GghrVtZt7Dz2"
      },
      "outputs": [],
      "source": [
        "clients_batched = dict()\n",
        "for (client_name, data) in clients.items():\n",
        "    clients_batched[client_name] = batch_data(data, BATCH_SIZE=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKTQH0jJ7GTQ"
      },
      "outputs": [],
      "source": [
        "def weight_scaling_factor(clients_trn_data, client_name):\n",
        "    client_names = list(clients_trn_data.keys())\n",
        "\n",
        "    global_count = sum([len(clients_trn_data[client_name]) for client_name in client_names])\n",
        "    local_count = len(clients_trn_data[client_name])\n",
        "\n",
        "    return local_count/global_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b1wHHTH7H7y"
      },
      "outputs": [],
      "source": [
        "def scale_model_parameter(parameter, scalar):\n",
        "    return parameter*scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmh32ubv7KM4"
      },
      "outputs": [],
      "source": [
        "def sum_scaled_weights(scaled_weights_list):\n",
        "    return sum(scaled_weights_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPttCUhZ7L7Y"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = self.fc1(x)\n",
        "        x = F.sigmoid(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.sigmoid(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTNxv5-97OMv"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, optimizer):\n",
        "    model.train()\n",
        "    for batch_idx, (image, label) in enumerate(train_loader):\n",
        "        image = image.to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(image)\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK8iyP-oN8uu"
      },
      "outputs": [],
      "source": [
        "def FedSGD(global_model, comm_rounds=10):\n",
        "    for comm_round in range(comm_rounds):\n",
        "        global_weight = {'fc1': global_model.fc1.weight.data, 'fc2':global_model.fc2.weight.data, 'fc3': global_model.fc3.weight.data}\n",
        "        global_bias = {'fc1': global_model.fc1.bias.data, 'fc2': global_model.fc2.bias.data, 'fc3': global_model.fc3.bias.data}\n",
        "\n",
        "        scaled_local_fc1_wieght_list = list()\n",
        "        scaled_local_fc1_bias_list = list()\n",
        "        scaled_local_fc2_wieght_list = list()\n",
        "        scaled_local_fc2_bias_list = list()\n",
        "        scaled_local_fc3_wieght_list = list()\n",
        "        scaled_local_fc3_bias_list = list()\n",
        "\n",
        "        client_names = list(clients_batched.keys())\n",
        "        random.shuffle(client_names)\n",
        "\n",
        "        for client_name in client_names:\n",
        "            local_model = Net().to(DEVICE)\n",
        "            local_optimizer = torch.optim.SGD(local_model.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "            local_model.fc1.weight.data = global_weight['fc1']\n",
        "            local_model.fc1.bias.data = global_bias['fc1']\n",
        "            local_model.fc2.weight.data = global_weight['fc2']\n",
        "            local_model.fc2.bias.data = global_bias['fc2']\n",
        "            local_model.fc3.weight.data = global_weight['fc3']\n",
        "            local_model.fc3.bias.data = global_bias['fc3']\n",
        "\n",
        "\n",
        "            train(local_model, clients_batched[client_name], local_optimizer)\n",
        "\n",
        "            scaling_factor = weight_scaling_factor(clients_batched, client_name)\n",
        "\n",
        "            scaled_fc1_weight = scale_model_parameter(local_model.fc1.weight.data, scaling_factor)\n",
        "            scaled_local_fc1_wieght_list.append(scaled_fc1_weight)\n",
        "            scaled_fc1_bias = scale_model_parameter(local_model.fc1.bias.data, scaling_factor)\n",
        "            scaled_local_fc1_bias_list.append(scaled_fc1_bias)\n",
        "\n",
        "            scaled_fc2_weight = scale_model_parameter(local_model.fc2.weight.data, scaling_factor)\n",
        "            scaled_local_fc2_wieght_list.append(scaled_fc2_weight)\n",
        "            scaled_fc2_bias = scale_model_parameter(local_model.fc2.bias.data, scaling_factor)\n",
        "            scaled_local_fc2_bias_list.append(scaled_fc2_bias)\n",
        "\n",
        "            scaled_fc3_weight = scale_model_parameter(local_model.fc3.weight.data, scaling_factor)\n",
        "            scaled_local_fc3_wieght_list.append(scaled_fc3_weight)\n",
        "            scaled_fc3_bias = scale_model_parameter(local_model.fc3.bias.data, scaling_factor)\n",
        "            scaled_local_fc3_bias_list.append(scaled_fc3_bias)\n",
        "\n",
        "        average_fc1_weight = sum_scaled_weights(scaled_local_fc1_wieght_list)\n",
        "        global_model.fc1.weight.data = average_fc1_weight\n",
        "        average_fc1_bias = sum_scaled_weights(scaled_local_fc1_bias_list)\n",
        "        global_model.fc1.bias.data = average_fc1_bias\n",
        "\n",
        "        average_fc2_weight = sum_scaled_weights(scaled_local_fc2_wieght_list)\n",
        "        global_model.fc2.weight.data = average_fc2_weight\n",
        "        average_fc2_bias = sum_scaled_weights(scaled_local_fc2_bias_list)\n",
        "        global_model.fc2.bias.data = average_fc2_bias\n",
        "\n",
        "        average_fc3_weight = sum_scaled_weights(scaled_local_fc3_wieght_list)\n",
        "        global_model.fc3.weight.data = average_fc3_weight\n",
        "        average_fc3_bias = sum_scaled_weights(scaled_local_fc3_bias_list)\n",
        "        global_model.fc3.bias.data = average_fc3_bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HONSghKd7P_q"
      },
      "outputs": [],
      "source": [
        "def FedAvg(global_model, C, EPOCHS=10, comm_rounds=10):\n",
        "    for comm_round in range(comm_rounds):\n",
        "        global_weight = {'fc1': global_model.fc1.weight.data, 'fc2':global_model.fc2.weight.data, 'fc3': global_model.fc3.weight.data}\n",
        "        global_bias = {'fc1': global_model.fc1.bias.data, 'fc2': global_model.fc2.bias.data, 'fc3': global_model.fc3.bias.data}\n",
        "\n",
        "        scaled_local_fc1_wieght_list = list()\n",
        "        scaled_local_fc1_bias_list = list()\n",
        "        scaled_local_fc2_wieght_list = list()\n",
        "        scaled_local_fc2_bias_list = list()\n",
        "        scaled_local_fc3_wieght_list = list()\n",
        "        scaled_local_fc3_bias_list = list()\n",
        "\n",
        "        m = int(max(C*len(clients_batched), 1))\n",
        "\n",
        "        client_names = list(clients_batched.keys())\n",
        "        client_names = random.sample(client_names, m)\n",
        "\n",
        "        for client_name in client_names:\n",
        "            local_model = Net().to(DEVICE)\n",
        "            local_optimizer = torch.optim.SGD(local_model.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "            local_model.fc1.weight.data = global_weight['fc1']\n",
        "            local_model.fc1.bias.data = global_bias['fc1']\n",
        "            local_model.fc2.weight.data = global_weight['fc2']\n",
        "            local_model.fc2.bias.data = global_bias['fc2']\n",
        "            local_model.fc3.weight.data = global_weight['fc3']\n",
        "            local_model.fc3.bias.data = global_bias['fc3']\n",
        "\n",
        "            for EPOCH in range(EPOCHS):\n",
        "              train(local_model, clients_batched[client_name], local_optimizer)\n",
        "\n",
        "            scaling_factor = weight_scaling_factor(clients_batched, client_name)\n",
        "\n",
        "            scaled_fc1_weight = scale_model_parameter(local_model.fc1.weight.data, scaling_factor)\n",
        "            scaled_local_fc1_wieght_list.append(scaled_fc1_weight)\n",
        "            scaled_fc1_bias = scale_model_parameter(local_model.fc1.bias.data, scaling_factor)\n",
        "            scaled_local_fc1_bias_list.append(scaled_fc1_bias)\n",
        "\n",
        "            scaled_fc2_weight = scale_model_parameter(local_model.fc2.weight.data, scaling_factor)\n",
        "            scaled_local_fc2_wieght_list.append(scaled_fc2_weight)\n",
        "            scaled_fc2_bias = scale_model_parameter(local_model.fc2.bias.data, scaling_factor)\n",
        "            scaled_local_fc2_bias_list.append(scaled_fc2_bias)\n",
        "\n",
        "            scaled_fc3_weight = scale_model_parameter(local_model.fc3.weight.data, scaling_factor)\n",
        "            scaled_local_fc3_wieght_list.append(scaled_fc3_weight)\n",
        "            scaled_fc3_bias = scale_model_parameter(local_model.fc3.bias.data, scaling_factor)\n",
        "            scaled_local_fc3_bias_list.append(scaled_fc3_bias)\n",
        "\n",
        "        average_fc1_weight = sum_scaled_weights(scaled_local_fc1_wieght_list)\n",
        "        global_model.fc1.weight.data = average_fc1_weight\n",
        "        average_fc1_bias = sum_scaled_weights(scaled_local_fc1_bias_list)\n",
        "        global_model.fc1.bias.data = average_fc1_bias\n",
        "\n",
        "        average_fc2_weight = sum_scaled_weights(scaled_local_fc2_wieght_list)\n",
        "        global_model.fc2.weight.data = average_fc2_weight\n",
        "        average_fc2_bias = sum_scaled_weights(scaled_local_fc2_bias_list)\n",
        "        global_model.fc2.bias.data = average_fc2_bias\n",
        "\n",
        "        average_fc3_weight = sum_scaled_weights(scaled_local_fc3_wieght_list)\n",
        "        global_model.fc3.weight.data = average_fc3_weight\n",
        "        average_fc3_bias = sum_scaled_weights(scaled_local_fc3_bias_list)\n",
        "        global_model.fc3.bias.data = average_fc3_bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LykuDFB-7SKk"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, label in test_loader:\n",
        "            image = image.to(DEVICE)\n",
        "            label = label.to(DEVICE)\n",
        "            output = model(image)\n",
        "            test_loss += criterion(output, label).item()\n",
        "            prediction = output.max(1, keepdim=True)[1]\n",
        "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
        "\n",
        "    test_loss /= (len(test_loader.dataset)/ BATCH_SIZE)\n",
        "    test_accuracy = 100. * correct/len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "-KVzfsTgTG_z",
        "outputId": "b7eff72d-14ec-4665-d937-632b7427a197"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b8614b97d3ee>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcomm_rounds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mFedSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomm_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomm_rounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mtest_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-8794ca56e3fd>\u001b[0m in \u001b[0;36mFedSGD\u001b[0;34m(global_model, comm_rounds)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclients_batched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclient_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mscaling_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_scaling_factor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclients_batched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-7568945c3be6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                 \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    945\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mset_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "baseline_model = Net().to(DEVICE)\n",
        "\n",
        "test_accuracies = list()\n",
        "\n",
        "for comm_rounds in range(0,100, 5):\n",
        "  FedSGD(baseline_model, comm_rounds=comm_rounds)\n",
        "  test_loss, test_accuracy = evaluate(baseline_model, test_loader)\n",
        "  test_accuracies.append(test_accuracy)\n",
        "\n",
        "plt.plot(range(0, 100, 5), test_accuracies)\n",
        "plt.xlabel('communication rounds')\n",
        "plt.ylabel('test accuracy(%)')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_NPY6Ra7UBT"
      },
      "outputs": [],
      "source": [
        "global_model = Net().to(DEVICE)\n",
        "\n",
        "global_test_accuracies = list()\n",
        "\n",
        "for comm_rounds in range(0,100, 5):\n",
        "  FedAvg(global_model, C=0.3, comm_rounds=comm_rounds)\n",
        "  test_loss, test_accuracy = evaluate(global_model, test_loader)\n",
        "  global_test_accuracies.append(test_accuracy)\n",
        "\n",
        "plt.plot(global_test_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R28kJQNWtHv1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "federatedlearning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
